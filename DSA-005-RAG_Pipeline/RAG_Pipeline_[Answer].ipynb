{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24063,"status":"ok","timestamp":1763031205372,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"Psox7IvHqm3Y","outputId":"7934be29-fa14-4f1b-fb4f-f8e10e68a8fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/18.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.1/18.1 MB\u001b[0m \u001b[31m183.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/18.1 MB\u001b[0m \u001b[31m193.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m216.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m216.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/318.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n","yfinance 0.2.66 requires websockets\u003e=13.0, but you have websockets 12.0 which is incompatible.\n","google-adk 1.17.0 requires websockets\u003c16.0.0,\u003e=15.0.1, but you have websockets 12.0 which is incompatible.\n","dataproc-spark-connect 0.8.3 requires websockets\u003e=14.0, but you have websockets 12.0 which is incompatible.\n","google-genai 1.49.0 requires websockets\u003c15.1.0,\u003e=13.0.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# 1. Installations\n","# This minimalist command installs only the essential libraries needed,\n","# respecting the stable versions in the Colab environment to avoid conflicts.\n","\n","!pip install \\\n","    \"langchain\u003e=0.3.0,\u003c0.4.0\" \\\n","    \"langchain-community\u003e=0.3.0,\u003c0.4.0\" \\\n","    \"langchain-openai\u003e=0.3.0,\u003c0.4.0\" \\\n","    \"faiss-cpu\u003e=1.8.0,\u003c1.13.0\" \\\n","    \"pypdf\u003e=4.0.0,\u003c5.0.0\" \\\n","    \"gradio==4.44.1\" \\\n","    \"python-dotenv\u003e=1.0.0,\u003c2.0.0\" \\\n","    \"pandas\u003e=2.0.0,\u003c3.0.0\" \\\n","    -q"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25409,"status":"ok","timestamp":1763031230785,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"et3s-C6Uqm_G","outputId":"e57eec07-30af-4504-b06a-6ef29b284074"},"outputs":[{"name":"stdout","output_type":"stream","text":["All libraries imported successfully.\n"]}],"source":["# 2. Imports (Complete)\n","# This cell contains all necessary imports for the entire project,\n","# including data handling, advanced retrieval, and the user interface.\n","\n","import os\n","import shutil\n","import pickle\n","import numpy as np\n","import pandas as pd\n","from dotenv import load_dotenv\n","from tqdm import tqdm\n","\n","# Core LangChain document and loader components\n","from langchain.docstore.document import Document\n","from langchain_community.document_loaders import PyPDFLoader\n","\n","# Text splitter for prose\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# Advanced retriever components\n","from langchain.retrievers import ParentDocumentRetriever\n","from langchain.storage import InMemoryStore\n","from langchain_community.docstore import InMemoryDocstore\n","import faiss\n","\n","# Vector store and embedding model\n","from langchain_community.vectorstores import FAISS\n","from langchain_openai import OpenAIEmbeddings\n","\n","# Language model and RAG chain\n","from langchain_openai import ChatOpenAI\n","from langchain.chains import RetrievalQA\n","\n","# Evaluation metric\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# User Interface\n","import gradio as gr\n","\n","# Google Colab specific for file downloads\n","from google.colab import files\n","\n","print(\"All libraries imported successfully.\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1763031230805,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"Av56PDx7qnFo","outputId":"7eb3e14b-356e-4cfc-a630-277bf93491ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Applying environment fix...\n","Environment fix applied.\n"]}],"source":["# 3. Environment Fix (Run Once)\n","# This cell permanently fixes the \"proxies\" validation error for this notebook session.\n","# It removes the conflicting proxy environment variables that Colab can sometimes set.\n","\n","print(\"Applying environment fix...\")\n","os.environ.pop('HTTP_PROXY', None)\n","os.environ.pop('HTTPS_PROXY', None)\n","print(\"Environment fix applied.\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1763031230830,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"KZke78kRqnNd","outputId":"0c9dffab-986f-43d6-b5fa-aab206348dd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["OpenAI API Key loaded successfully.\n"]}],"source":["# 1.1 Load API Key and Define Paths\n","# Loads the OpenAI API key from the `template.env` file and defines key folder paths.\n","\n","load_dotenv('template.env')\n","OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n","\n","if not OPENAI_API_KEY:\n","    raise ValueError(\"OpenAI API key not found. Please set it in 'template.env'.\")\n","else:\n","    print(\"OpenAI API Key loaded successfully.\")\n","\n","DATA_PATH = \"docs/\"\n","VECTOR_STORE_PATH = \"vector_store/\""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24734,"status":"ok","timestamp":1763031255567,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"zklR-47Zqytp","outputId":"cab336d1-2c50-40d5-ee49-855a29c7be41"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading documents with dynamic CSV summaries...\n"]},{"name":"stderr","output_type":"stream","text":["Processing files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:24\u003c00:00,  6.20s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Loaded 254 pages from PDFs.\n","Created 40 summarized, structured chunks from CSVs.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# 2.1 Load Documents (with Fully Dynamic CSV Summaries)\n","# This cell uses an advanced function that automatically analyzes any ingested CSV.\n","# It identifies key numeric and categorical columns on the fly to generate a rich,\n","# context-aware summary for each chunk, maximizing retrieval accuracy without\n","# prior knowledge of the file's schema.\n","\n","print(\"Loading documents with dynamic CSV summaries...\")\n","\n","pdf_documents = []\n","csv_derived_documents = []\n","files_to_process = []\n","\n","def process_csv_to_markdown_documents(file_path, rows_per_chunk=25, max_key_cols=8):\n","    \"\"\"\n","    Loads a CSV and creates documents with a markdown table and a dynamically\n","    generated natural language summary of the chunk's most relevant columns.\n","    \"\"\"\n","    try:\n","        df = pd.read_csv(file_path)\n","        filename = os.path.basename(file_path)\n","\n","        # --- Auto-detect column types ---\n","        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n","        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n","\n","        for i in range(0, len(df), rows_per_chunk):\n","            chunk_df = df.iloc[i:i + rows_per_chunk]\n","\n","            # --- Dynamically Generate Summary ---\n","            summary_parts = [f\"This chunk from '{filename}' contains {len(chunk_df)} records.\"]\n","\n","            # Summarize a subset of the most relevant columns to keep it concise\n","            for col in numeric_cols[:max_key_cols]:\n","                summary_parts.append(f\"'{col}' ranges from {chunk_df[col].min()} to {chunk_df[col].max()}.\")\n","\n","            for col in categorical_cols[:max_key_cols]:\n","                # Exclude high-cardinality columns (likely IDs) from summary\n","                if chunk_df[col].nunique(dropna=True) \u003c len(chunk_df) * 0.8:\n","                    top_values = chunk_df[col].value_counts().nlargest(2).index.tolist()\n","                    summary_parts.append(f\"Key '{col}' values include: {', '.join(map(str, top_values))}.\")\n","\n","            summary = \" \".join(summary_parts)\n","            markdown_table = chunk_df.to_markdown(index=False)\n","\n","            # --- Create Final Document Content ---\n","            final_content = f\"Summary: {summary}\\n\\n---\\n\\n{markdown_table}\"\n","\n","            doc = Document(\n","                page_content=final_content,\n","                metadata={\"source\": file_path, \"row_start\": i}\n","            )\n","            csv_derived_documents.append(doc)\n","\n","    except Exception as e:\n","        print(f\"Error processing CSV file {file_path}: {e}\")\n","\n","# --- Main Loading Loop ---\n","for root, _, filenames in os.walk(DATA_PATH):\n","    for file in filenames:\n","        if file.endswith((\".pdf\", \".csv\")):\n","            files_to_process.append(os.path.join(root, file))\n","\n","for file_path in tqdm(files_to_process, desc=\"Processing files\"):\n","    if file_path.endswith(\".pdf\"):\n","        try:\n","            loader = PyPDFLoader(file_path)\n","            pdf_documents.extend(loader.load())\n","        except Exception as e:\n","            print(f\"Error loading PDF {file_path}: {e}\")\n","    elif file_path.endswith(\".csv\"):\n","        process_csv_to_markdown_documents(file_path)\n","\n","print(f\"\\nLoaded {len(pdf_documents)} pages from PDFs.\")\n","print(f\"Created {len(csv_derived_documents)} summarized, structured chunks from CSVs.\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11983,"status":"ok","timestamp":1763031267552,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"838fe380","outputId":"7241dce0-66e6-4fe2-ea69-e5a8dbe3e1b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Could not retrieve API key from Colab Secrets Manager: Secret OPENAI_API_KEY does not exist.\n","Please enter your OpenAI API key: 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\n","API key entered manually.\n","OpenAI API key has been written to template.env\n"]}],"source":["import os\n","from google.colab import userdata\n","\n","# Use Colab's userdata feature to securely store the API key\n","try:\n","    # Attempt to get the API key from userdata first\n","    openai_api_key = userdata.get('OPENAI_API_KEY')\n","    print(\"Using API key from Colab Secrets Manager.\")\n","except Exception as e:\n","    # If not found in userdata, prompt the user\n","    print(f\"Could not retrieve API key from Colab Secrets Manager: {e}\")\n","    openai_api_key = input(\"Please enter your OpenAI API key: \")\n","    print(\"API key entered manually.\")\n","\n","\n","# Write the API key to the template.env file\n","with open('template.env', 'w') as f:\n","    f.write(f'OPENAI_API_KEY={openai_api_key}\\n')\n","\n","print(\"OpenAI API key has been written to template.env\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1763031267584,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"ea326a72","outputId":"265346da-e9e9-48f8-b1b4-4a68d160d060"},"outputs":[{"name":"stdout","output_type":"stream","text":["OPENAI_API_KEY=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\n","\n"]}],"source":["with open('/content/template.env', 'r') as f:\n","    print(f.read())"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32354,"status":"ok","timestamp":1763031299941,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"nQLEGglSq0KW","outputId":"b0dd70c5-a3ff-4c97-ff55-7bd6b4b369b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Setting up advanced retriever...\n","Adding documents to the retriever...\n","Advanced retriever created successfully.\n"]}],"source":["# 2.2 Create Advanced Retriever and Vector Store\n","# This cell uses the ParentDocumentRetriever to solve the retrieval problem by\n","# embedding small, retrieval-friendly chunks while retrieving larger,\n","# context-rich parent documents for the LLM.\n","\n","print(\"Setting up advanced retriever...\")\n","\n","all_docs = pdf_documents + csv_derived_documents\n","\n","parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1200)\n","child_splitter = RecursiveCharacterTextSplitter(chunk_size=300)\n","\n","embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, chunk_size=900)\n","embedding_dimension = len(embeddings.embed_query(\"test\"))\n","index = faiss.IndexFlatL2(embedding_dimension)\n","\n","faiss_docstore = InMemoryDocstore()\n","vectorstore = FAISS(\n","    embedding_function=embeddings,\n","    index=index,\n","    docstore=faiss_docstore,\n","    index_to_docstore_id={}\n",")\n","\n","store = InMemoryStore()\n","\n","retriever = ParentDocumentRetriever(\n","    vectorstore=vectorstore,\n","    docstore=store,\n","    child_splitter=child_splitter,\n","    parent_splitter=parent_splitter,\n",")\n","\n","print(\"Adding documents to the retriever...\")\n","retriever.add_documents(all_docs, ids=None)\n","\n","print(\"Advanced retriever created successfully.\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":120,"status":"ok","timestamp":1763031300058,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"M34Wg3IJq1yf","outputId":"bda25a0a-9e84-4157-ce54-8172a01f4aac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving retriever components...\n","Retriever components saved to 'vector_store/'.\n"]}],"source":["# 2.3 Save Retriever Components\n","# This cell saves the FAISS vector store and the parent document store\n","# so you don't have to re-process documents every time.\n","\n","print(\"Saving retriever components...\")\n","\n","retriever.vectorstore.save_local(VECTOR_STORE_PATH)\n","\n","with open(os.path.join(VECTOR_STORE_PATH, \"parent_docstore.pkl\"), \"wb\") as f:\n","    pickle.dump(retriever.docstore, f)\n","\n","print(f\"Retriever components saved to '{VECTOR_STORE_PATH}'.\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":510,"status":"ok","timestamp":1763031300578,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"uuIWzNN7q3O9","outputId":"f82dd319-abe3-4c20-ca4b-13a39b2722b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading retriever components...\n","Retriever components loaded successfully.\n"]}],"source":["# 3.1 Load Retriever Components\n","# This cell loads the pre-built retriever components, allowing you to\n","# skip the time-consuming ingestion and embedding steps.\n","\n","print(\"Loading retriever components...\")\n","\n","embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, chunk_size=900)\n","\n","# Load the vector store\n","vectorstore = FAISS.load_local(\n","    VECTOR_STORE_PATH,\n","    embeddings,\n","    allow_dangerous_deserialization=True\n",")\n","\n","# Load the parent document store\n","with open(os.path.join(VECTOR_STORE_PATH, \"parent_docstore.pkl\"), \"rb\") as f:\n","    store = pickle.load(f)\n","\n","# Recreate the ParentDocumentRetriever\n","# Note: Splitters are not saved, so they must be re-initialized.\n","parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1200)\n","child_splitter = RecursiveCharacterTextSplitter(chunk_size=300)\n","\n","retriever = ParentDocumentRetriever(\n","    vectorstore=vectorstore,\n","    docstore=store,\n","    child_splitter=child_splitter,\n","    parent_splitter=parent_splitter,\n",")\n","\n","print(\"Retriever components loaded successfully.\")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":92,"status":"ok","timestamp":1763031300672,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"J_k_MN79q4q5","outputId":"7a37162f-e465-4c1e-b58e-fada28951ef0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating the RAG chain...\n","RAG chain created successfully.\n"]}],"source":["# 4.1 Create the RetrievalQA Chain\n","# This cell uses the advanced ParentDocumentRetriever directly.\n","\n","print(\"Creating the RAG chain...\")\n","\n","llm = ChatOpenAI(\n","    model_name='gpt-3.5-turbo',\n","    temperature=0.1,\n","    openai_api_key=OPENAI_API_KEY,\n",")\n","\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm=llm,\n","    chain_type=\"stuff\",\n","    retriever=retriever,\n","    return_source_documents=True\n",")\n","\n","print(\"RAG chain created successfully.\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13436,"status":"ok","timestamp":1763031314122,"user":{"displayName":"Divya GV","userId":"17016729920807174151"},"user_tz":-480},"id":"SCBfkJwLq6Kt","outputId":"2fa0f129-8f1b-46b0-d7f0-1f609ff17574"},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting evaluation...\n","\n","--- Running Evaluation ---\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating Queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12\u003c00:00,  4.29s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","--- Detailed Evaluation Report ---\n","\n","Query: What are the three core clinical features of dementia with Lewy bodies (DLB)?\n","Ground Truth: The core clinical features for dementia with Lewy bodies are fluctuating cognition, recurrent visual hallucinations, and spontaneous parkinsonism.\n","Generated Answer: The three core clinical features of dementia with Lewy bodies (DLB) are:\n","\n","1. Fluctuating cognition: This refers to unpredictable changes in attention and alertness.\n","2. Visual hallucinations: Seeing things that are not present.\n","3. Parkinsonism: Symptoms similar to Parkinson's disease, such as tremors, stiffness, and slow movement.\n","\n","These features are used to help diagnose DLB, along with other symptoms like REM sleep behavior disorder and sensitivity to antipsychotic medications.\n","Semantic Similarity Score: 0.9536\n","------------------------------\n","Query: What does the data show about the cognitive scores for subjects with a positive APOE_Îµ4 gene?\n","Ground Truth: The data includes subjects with a positive APOE_Îµ4 gene, and their cognitive test scores vary, with some showing low scores indicative of cognitive impairment.\n","Generated Answer: The data does not provide specific information about the cognitive scores for subjects with a positive APOE_Îµ4 gene.\n","Semantic Similarity Score: 0.9228\n","------------------------------\n","Query: According to the data, is there a link between 'Sedentary' physical activity and a 'Poor' sleep quality?\n","Ground Truth: The dataset contains records for subjects with various physical activity levels and sleep qualities. By retrieving this data, one can observe if a pattern or correlation exists between sedentary behavior and poor sleep.\n","Generated Answer: Based on the provided context, there is a link between lower linkage in couples' daily somatic activity (e.g., synchronized movement measured from wrist sensors) and higher caregiver anxiety. However, the data does not specifically mention a direct link between sedentary physical activity and poor sleep quality.\n","Semantic Similarity Score: 0.8684\n","------------------------------\n","\n","--- Final Summary ---\n","Average Semantic Similarity: 0.9149\n","Accuracy (at \u003e0.75 similarity): 100.00%\n","\n","Evaluation complete.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# 4.2 Run Evaluation (Complete)\n","# This cell evaluates the RAG chain's performance on a predefined set of questions\n","# tailored to a dementia-related dataset. It calculates semantic similarity\n","# and prints a detailed report.\n","\n","print(\"Starting evaluation...\")\n","\n","evaluation_set = [\n","    {\n","        \"query\": \"What are the three core clinical features of dementia with Lewy bodies (DLB)?\",\n","        \"ground_truth_answer\": \"The core clinical features for dementia with Lewy bodies are fluctuating cognition, recurrent visual hallucinations, and spontaneous parkinsonism.\"\n","    },\n","    {\n","        \"query\": \"What does the data show about the cognitive scores for subjects with a positive APOE_Îµ4 gene?\",\n","        \"ground_truth_answer\": \"The data includes subjects with a positive APOE_Îµ4 gene, and their cognitive test scores vary, with some showing low scores indicative of cognitive impairment.\"\n","    },\n","    {\n","        \"query\": \"According to the data, is there a link between 'Sedentary' physical activity and a 'Poor' sleep quality?\",\n","        \"ground_truth_answer\": \"The dataset contains records for subjects with various physical activity levels and sleep qualities. By retrieving this data, one can observe if a pattern or correlation exists between sedentary behavior and poor sleep.\"\n","    }\n","]\n","\n","results = []\n","total_similarity_score = 0\n","\n","print(\"\\n--- Running Evaluation ---\")\n","for item in tqdm(evaluation_set, desc=\"Evaluating Queries\"):\n","    query = item[\"query\"]\n","    ground_truth = item[\"ground_truth_answer\"]\n","\n","    # Get the answer from the RAG chain\n","    response = qa_chain.invoke({\"query\": query})\n","    generated_answer = response['result']\n","\n","    # Embed both the generated answer and the ground-truth answer\n","    generated_embedding = embeddings.embed_query(generated_answer)\n","    ground_truth_embedding = embeddings.embed_query(ground_truth)\n","\n","    # Calculate cosine similarity\n","    similarity = cosine_similarity(\n","        np.array(generated_embedding).reshape(1, -1),\n","        np.array(ground_truth_embedding).reshape(1, -1)\n","    )[0][0]\n","\n","    results.append({\n","        \"query\": query,\n","        \"ground_truth\": ground_truth,\n","        \"generated_answer\": generated_answer,\n","        \"similarity_score\": similarity\n","    })\n","    total_similarity_score += similarity\n","\n","# --- Print Detailed Results ---\n","print(\"\\n--- Detailed Evaluation Report ---\\n\")\n","for res in results:\n","    print(f\"Query: {res['query']}\")\n","    print(f\"Ground Truth: {res['ground_truth']}\")\n","    print(f\"Generated Answer: {res['generated_answer']}\")\n","    print(f\"Semantic Similarity Score: {res['similarity_score']:.4f}\")\n","    print(\"-\" * 30)\n","\n","# --- Print Final Summary ---\n","average_similarity = total_similarity_score / len(evaluation_set)\n","print(f\"\\n--- Final Summary ---\")\n","print(f\"Average Semantic Similarity: {average_similarity:.4f}\")\n","\n","similarity_threshold = 0.75\n","accurate_predictions = sum(1 for res in results if res['similarity_score'] \u003e= similarity_threshold)\n","accuracy = (accurate_predictions / len(evaluation_set)) * 100\n","print(f\"Accuracy (at \u003e{similarity_threshold} similarity): {accuracy:.2f}%\")\n","\n","print(\"\\nEvaluation complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":613},"id":"MvmsawHzq7px"},"outputs":[{"name":"stdout","output_type":"stream","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://24cbc0029839bdb012.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://24cbc0029839bdb012.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# 5.1 Launch the Gradio UI (using ChatInterface)\n","# This cell uses the simpler and more robust gr.ChatInterface, which handles\n","# chat history automatically and places sources in a collapsible accordion.\n","\n","def ask_question_for_chat_interface(query, history):\n","    \"\"\"\n","    This function is adapted for gr.ChatInterface. It takes a query and history,\n","    calls the RAG chain, and returns a single response string with formatted sources.\n","    \"\"\"\n","    try:\n","        result = qa_chain.invoke({\"query\": query})\n","        answer = result.get('result', 'Sorry, I could not find an answer.')\n","\n","        sources_text = \"\"\n","        source_docs = result.get('source_documents', [])\n","\n","        if source_docs:\n","            unique_sources = set()\n","            for doc in source_docs:\n","                source_name = os.path.basename(doc.metadata.get('source', 'Unknown'))\n","                page_number = doc.metadata.get('page')\n","                if page_number is not None:\n","                    unique_sources.add(f\"*{source_name}* (p. {page_number + 1})\")\n","                else:\n","                    unique_sources.add(f\"*{source_name}*\")\n","\n","            if unique_sources:\n","                source_count = len(unique_sources)\n","                sources_text = f\"\\n\\n\u003cdetails\u003e\u003csummary\u003e\u003cstrong\u003eSources ({source_count})\u003c/strong\u003e\u003c/summary\u003e\\n\\n\"\n","                sources_text += \"- \" + \"\\n- \".join(sorted(list(unique_sources)))\n","                sources_text += \"\\n\\n\u003c/details\u003e\"\n","\n","        full_response = answer + sources_text\n","        return full_response\n","\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","        return f\"An error occurred while processing your request: {e}\"\n","\n","# --- Create and Launch the ChatInterface ---\n","demo = gr.ChatInterface(\n","    fn=ask_question_for_chat_interface,\n","    title=\"ğŸ¤– RAG Chatbot for Dementia Reports\",\n","    description=\"Ask a question about the uploaded documents. The chatbot will maintain a history of your conversation.\",\n","    examples=[\n","        \"What does the data suggest about the relationship between AlcoholLevel and Cognitive_Test_Scores?\",\n","        \"Compare the average HeartRate for subjects with Sedentary vs. Moderate Activity levels.\",\n","        \"What chronic health conditions are most common in patients with low cognitive scores?\",\n","    ],\n","    cache_examples=False,\n","    theme=\"soft\"\n",")\n","\n","demo.launch(debug=True, share=True)"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}