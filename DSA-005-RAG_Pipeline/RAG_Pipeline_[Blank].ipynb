{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Installations\n",
        "# This minimalist command installs only the essential libraries needed,\n",
        "# respecting the stable versions in the Colab environment to avoid conflicts.\n",
        "\n",
        "!pip install \\\n",
        "    \"langchain>=0.3.0,<0.4.0\" \\\n",
        "    \"langchain-community>=0.3.0,<0.4.0\" \\\n",
        "    \"langchain-openai>=0.3.0,<0.4.0\" \\\n",
        "    \"faiss-cpu>=1.8.0,<1.13.0\" \\\n",
        "    \"pypdf>=4.0.0,<5.0.0\" \\\n",
        "    \"gradio==4.44.1\" \\\n",
        "    \"python-dotenv>=1.0.0,<2.0.0\" \\\n",
        "    \"pandas>=2.0.0,<3.0.0\" \\\n",
        "    -q"
      ],
      "metadata": {
        "id": "Psox7IvHqm3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Imports (Complete)\n",
        "# This cell contains all necessary imports for the entire project,\n",
        "# including data handling, advanced retrieval, and the user interface.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Core LangChain document and loader components\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Text splitter for prose\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Advanced retriever components\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_community.docstore import InMemoryDocstore\n",
        "import faiss\n",
        "\n",
        "# Vector store and embedding model\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Language model and RAG chain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Evaluation metric\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# User Interface\n",
        "import gradio as gr\n",
        "\n",
        "# Google Colab specific for file downloads\n",
        "from google.colab import files\n",
        "\n",
        "print(\"All libraries imported successfully.\")"
      ],
      "metadata": {
        "id": "et3s-C6Uqm_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Environment Fix (Run Once)\n",
        "# This cell permanently fixes the \"proxies\" validation error for this notebook session.\n",
        "# It removes the conflicting proxy environment variables that Colab can sometimes set.\n",
        "\n",
        "print(\"Applying environment fix...\")\n",
        "os.environ.pop('HTTP_PROXY', None)\n",
        "os.environ.pop('HTTPS_PROXY', None)\n",
        "print(\"Environment fix applied.\")"
      ],
      "metadata": {
        "id": "Av56PDx7qnFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1 Load API Key and Define Paths\n",
        "# Loads the OpenAI API key from the `template.env` file and defines key folder paths.\n",
        "\n",
        "load_dotenv('template.env')\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    raise ValueError(\"OpenAI API key not found. Please set it in 'template.env'.\")\n",
        "else:\n",
        "    print(\"OpenAI API Key loaded successfully.\")\n",
        "\n",
        "DATA_PATH = \"docs/\"\n",
        "VECTOR_STORE_PATH = \"vector_store/\""
      ],
      "metadata": {
        "id": "KZke78kRqnNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2 Run Evaluation (Complete)\n",
        "# This cell evaluates the RAG chain's performance on a predefined set of questions\n",
        "# tailored to a dementia-related dataset. It calculates semantic similarity\n",
        "# and prints a detailed report.\n",
        "\n",
        "print(\"Starting evaluation...\")\n",
        "\n",
        "evaluation_set = [\n",
        "    {\n",
        "        \"query\": \"What are the three core clinical features of dementia with Lewy bodies (DLB)?\",\n",
        "        \"ground_truth_answer\": \"The core clinical features for dementia with Lewy bodies are fluctuating cognition, recurrent visual hallucinations, and spontaneous parkinsonism.\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What does the data show about the cognitive scores for subjects with a positive APOE_Îµ4 gene?\",\n",
        "        \"ground_truth_answer\": \"The data includes subjects with a positive APOE_Îµ4 gene, and their cognitive test scores vary, with some showing low scores indicative of cognitive impairment.\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"According to the data, is there a link between 'Sedentary' physical activity and a 'Poor' sleep quality?\",\n",
        "        \"ground_truth_answer\": \"The dataset contains records for subjects with various physical activity levels and sleep qualities. By retrieving this data, one can observe if a pattern or correlation exists between sedentary behavior and poor sleep.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "results = []\n",
        "total_similarity_score = 0\n",
        "\n",
        "print(\"\\n--- Running Evaluation ---\")\n",
        "for item in tqdm(evaluation_set, desc=\"Evaluating Queries\"):\n",
        "    query = item[\"query\"]\n",
        "    ground_truth = item[\"ground_truth_answer\"]\n",
        "\n",
        "    # Get the answer from the RAG chain\n",
        "    response = qa_chain.invoke({\"query\": query})\n",
        "    generated_answer = response['result']\n",
        "\n",
        "    # Embed both the generated answer and the ground-truth answer\n",
        "    generated_embedding = embeddings.embed_query(generated_answer)\n",
        "    ground_truth_embedding = embeddings.embed_query(ground_truth)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity = cosine_similarity(\n",
        "        np.array(generated_embedding).reshape(1, -1),\n",
        "        np.array(ground_truth_embedding).reshape(1, -1)\n",
        "    )[0][0]\n",
        "\n",
        "    results.append({\n",
        "        \"query\": query,\n",
        "        \"ground_truth\": ground_truth,\n",
        "        \"generated_answer\": generated_answer,\n",
        "        \"similarity_score\": similarity\n",
        "    })\n",
        "    total_similarity_score += similarity\n",
        "\n",
        "# --- Print Detailed Results ---\n",
        "print(\"\\n--- Detailed Evaluation Report ---\\n\")\n",
        "for res in results:\n",
        "    print(f\"Query: {res['query']}\")\n",
        "    print(f\"Ground Truth: {res['ground_truth']}\")\n",
        "    print(f\"Generated Answer: {res['generated_answer']}\")\n",
        "    print(f\"Semantic Similarity Score: {res['similarity_score']:.4f}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# --- Print Final Summary ---\n",
        "average_similarity = total_similarity_score / len(evaluation_set)\n",
        "print(f\"\\n--- Final Summary ---\")\n",
        "print(f\"Average Semantic Similarity: {average_similarity:.4f}\")\n",
        "\n",
        "similarity_threshold = 0.75\n",
        "accurate_predictions = sum(1 for res in results if res['similarity_score'] >= similarity_threshold)\n",
        "accuracy = (accurate_predictions / len(evaluation_set)) * 100\n",
        "print(f\"Accuracy (at >{similarity_threshold} similarity): {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nEvaluation complete.\")"
      ],
      "metadata": {
        "id": "SCBfkJwLq6Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 Launch the Gradio UI (using ChatInterface)\n",
        "# This cell uses the simpler and more robust gr.ChatInterface, which handles\n",
        "# chat history automatically and places sources in a collapsible accordion.\n",
        "\n",
        "def ask_question_for_chat_interface(query, history):\n",
        "    \"\"\"\n",
        "    This function is adapted for gr.ChatInterface. It takes a query and history,\n",
        "    calls the RAG chain, and returns a single response string with formatted sources.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = qa_chain.invoke({\"query\": query})\n",
        "        answer = result.get('result', 'Sorry, I could not find an answer.')\n",
        "\n",
        "        sources_text = \"\"\n",
        "        source_docs = result.get('source_documents', [])\n",
        "\n",
        "        if source_docs:\n",
        "            unique_sources = set()\n",
        "            for doc in source_docs:\n",
        "                source_name = os.path.basename(doc.metadata.get('source', 'Unknown'))\n",
        "                page_number = doc.metadata.get('page')\n",
        "                if page_number is not None:\n",
        "                    unique_sources.add(f\"*{source_name}* (p. {page_number + 1})\")\n",
        "                else:\n",
        "                    unique_sources.add(f\"*{source_name}*\")\n",
        "\n",
        "            if unique_sources:\n",
        "                source_count = len(unique_sources)\n",
        "                sources_text = f\"\\n\\n<details><summary><strong>Sources ({source_count})</strong></summary>\\n\\n\"\n",
        "                sources_text += \"- \" + \"\\n- \".join(sorted(list(unique_sources)))\n",
        "                sources_text += \"\\n\\n</details>\"\n",
        "\n",
        "        full_response = answer + sources_text\n",
        "        return full_response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return f\"An error occurred while processing your request: {e}\"\n",
        "\n",
        "# --- Create and Launch the ChatInterface ---\n",
        "demo = gr.ChatInterface(\n",
        "    fn=ask_question_for_chat_interface,\n",
        "    title=\"ðŸ¤– RAG Chatbot for Dementia Reports\",\n",
        "    description=\"Ask a question about the uploaded documents. The chatbot will maintain a history of your conversation.\",\n",
        "    examples=[\n",
        "        \"What does the data suggest about the relationship between AlcoholLevel and Cognitive_Test_Scores?\",\n",
        "        \"Compare the average HeartRate for subjects with Sedentary vs. Moderate Activity levels.\",\n",
        "        \"What chronic health conditions are most common in patients with low cognitive scores?\",\n",
        "    ],\n",
        "    cache_examples=False,\n",
        "    theme=\"soft\"\n",
        ")\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "id": "MvmsawHzq7px"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}